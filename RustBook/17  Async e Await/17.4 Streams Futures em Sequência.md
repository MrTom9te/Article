# Streams: Futures em Sequência

Até agora neste capítulo, nos concentramos principalmente em futures individuais. A grande exceção foi o canal assíncrono que usamos. Lembre-se de como usamos o receptor para nosso canal assíncrono anteriormente neste capítulo na seção "Passagem de Mensagens". O método assíncrono `recv` produz uma sequência de itens ao longo do tempo. Este é um exemplo de um padrão muito mais geral conhecido como _stream_.

Vimos uma sequência de itens no Capítulo 13, quando examinamos a trait `Iterator` na seção "A Trait Iterator e o Método `next`", mas existem duas diferenças entre iteradores e o receptor do canal assíncrono. A primeira diferença é o tempo: iteradores são síncronos, enquanto o receptor do canal é assíncrono. A segunda é a API. Ao trabalhar diretamente com `Iterator`, chamamos seu método síncrono `next`. Com o stream `trpl::Receiver` em particular, chamamos um método assíncrono `recv` em vez disso. De resto, essas APIs se sentem muito semelhantes, e essa semelhança não é coincidência. Um stream é como uma forma assíncrona de iteração. Enquanto o `trpl::Receiver` especificamente espera para receber mensagens, a API de stream de uso geral é muito mais ampla: ela fornece o próximo item da mesma forma que `Iterator` faz, mas de forma assíncrona.

A semelhança entre iteradores e streams em Rust significa que podemos realmente criar um stream a partir de qualquer iterador. Assim como com um iterador, podemos trabalhar com um stream chamando seu método `next` e depois aguardando a saída, como na Listagem 17-30.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

fn main() {
    trpl::run(async {
        let values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
        let iter = values.iter().map(|n| n * 2);
        let mut stream = trpl::stream_from_iter(iter);

        while let Some(value) = stream.next().await {
            println!("O valor era: {value}");
        }
    });
}
```

Listagem 17-30: Criando um stream a partir de um iterador e imprimindo seus valores

Começamos com um array de números, que convertemos em um iterador e depois chamamos `map` nele para dobrar todos os valores. Em seguida, convertemos o iterador em um stream usando a função `trpl::stream_from_iter`. Depois, percorremos os itens no stream à medida que eles chegam com o loop `while let`.

Infelizmente, quando tentamos executar o código, ele não compila, mas em vez disso, relata que não há método `next` disponível:

```
error[E0599]: no method named `next` found for struct `Iter` in the current scope
  --> src/main.rs:10:40
   |
10 |         while let Some(value) = stream.next().await {
   |                                        ^^^^
   |
   = note: the full type name has been written to 'file:///projects/async_await/target/debug/deps/async_await-9de943556a6001b8.long-type-1281356139287206597.txt'
   = note: consider using `--verbose` to print the full type name to the console
   = help: items from traits can only be used if the trait is in scope
help: the following traits which provide `next` are implemented but not in scope; perhaps you want to import one of them
   |
1  + use crate::trpl::StreamExt;
   |
1  + use futures_util::stream::stream::StreamExt;
   |
1  + use std::iter::Iterator;
   |
1  + use std::str::pattern::Searcher;
   |
help: there is a method `try_next` with a similar name
   |
10 |         while let Some(value) = stream.try_next().await {
   |                                        ~~~~~~~~
```

Como esta saída explica, a razão para o erro do compilador é que precisamos da trait correta no escopo para poder usar o método `next`. Dada nossa discussão até agora, você pode razoavelmente esperar que essa trait seja `Stream`, mas é na verdade `StreamExt`. Abreviação de _extension_ (extensão), `Ext` é um padrão comum na comunidade Rust para estender uma trait com outra.

Explicaremos as traits `Stream` e `StreamExt` com um pouco mais de detalhes no final do capítulo, mas por enquanto, tudo o que você precisa saber é que a trait `Stream` define uma interface de baixo nível que efetivamente combina as traits `Iterator` e `Future`. `StreamExt` fornece um conjunto de APIs de nível superior além de `Stream`, incluindo o método `next` assim como outros métodos utilitários semelhantes aos fornecidos pela trait `Iterator`. `Stream` e `StreamExt` ainda não fazem parte da biblioteca padrão do Rust, mas a maioria dos crates do ecossistema usa a mesma definição.

A correção para o erro do compilador é adicionar uma declaração `use` para `trpl::StreamExt`, como na Listagem 17-31.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use trpl::StreamExt;

fn main() {
    trpl::run(async {
        let values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
        let iter = values.iter().map(|n| n * 2);
        let mut stream = trpl::stream_from_iter(iter);

        while let Some(value) = stream.next().await {
            println!("O valor era: {value}");
        }
    });
}
```

Listagem 17-31: Usando com sucesso um iterador como base para um stream

Com todas essas peças juntas, este código funciona da maneira que queremos! Além disso, agora que temos `StreamExt` no escopo, podemos usar todos os seus métodos utilitários, assim como com iteradores. Por exemplo, na Listagem 17-32, usamos o método `filter` para filtrar tudo, exceto múltiplos de três e cinco.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use trpl::StreamExt;

fn main() {
    trpl::run(async {
        let values = 1..101;
        let iter = values.map(|n| n * 2);
        let stream = trpl::stream_from_iter(iter);

        let mut filtered =
            stream.filter(|value| value % 3 == 0 || value % 5 == 0);

        while let Some(value) = filtered.next().await {
            println!("O valor era: {value}");
        }
    });
}
```

Listagem 17-32: Filtrando um stream com o método `StreamExt::filter`

Claro, isso não é muito interessante, já que poderíamos fazer o mesmo com iteradores normais e sem nenhum async. Vamos examinar o que podemos fazer que _é_ exclusivo para streams.

## Compondo Streams

Muitos conceitos são naturalmente representados como streams: itens se tornando disponíveis em uma fila, pedaços de dados sendo extraídos incrementalmente do sistema de arquivos quando o conjunto de dados completo é grande demais para a memória do computador, ou dados chegando pela rede ao longo do tempo. Como streams são futures, podemos usá-los com qualquer outro tipo de future e combiná-los de maneiras interessantes. Por exemplo, podemos agrupar eventos para evitar acionar muitas chamadas de rede, definir timeouts em sequências de operações de longa duração, ou limitar eventos de interface do usuário para evitar fazer trabalho desnecessário.

Vamos começar construindo um pequeno stream de mensagens como substituto de um stream de dados que poderíamos ver de um WebSocket ou outro protocolo de comunicação em tempo real, como mostrado na Listagem 17-33.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let mut messages = get_messages();

        while let Some(message) = messages.next().await {
            println!("{message}");
        }
    });
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
    for message in messages {
        tx.send(format!("Mensagem: '{message}'")).unwrap();
    }

    ReceiverStream::new(rx)
}
```

Listagem 17-33: Usando o receptor `rx` como um `ReceiverStream`

Primeiro, criamos uma função chamada `get_messages` que retorna `impl Stream<Item = String>`. Para sua implementação, criamos um canal assíncrono, percorremos as 10 primeiras letras do alfabeto inglês e as enviamos pelo canal.

Também usamos um novo tipo: `ReceiverStream`, que converte o receptor `rx` do `trpl::channel` em um `Stream` com um método `next`. De volta ao `main`, usamos um loop `while let` para imprimir todas as mensagens do stream.

Quando executamos este código, obtemos exatamente os resultados que esperaríamos:

```
Mensagem: 'a'
Mensagem: 'b'
Mensagem: 'c'
Mensagem: 'd'
Mensagem: 'e'
Mensagem: 'f'
Mensagem: 'g'
Mensagem: 'h'
Mensagem: 'i'
Mensagem: 'j'
```

Novamente, poderíamos fazer isso com a API `Receiver` regular ou até mesmo com a API `Iterator` regular, então vamos adicionar um recurso que requer streams: adicionar um timeout que se aplica a cada item no stream e um atraso nos itens que emitimos, como mostrado na Listagem 17-34.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::{pin::pin, time::Duration};
use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let mut messages =
            pin!(get_messages().timeout(Duration::from_millis(200)));

        while let Some(result) = messages.next().await {
            match result {
                Ok(message) => println!("{message}"),
                Err(reason) => eprintln!("Problema: {reason:?}"),
            }
        }
    })
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
    for message in messages {
        tx.send(format!("Mensagem: '{message}'")).unwrap();
    }

    ReceiverStream::new(rx)
}
```

Listagem 17-34: Usando o método `StreamExt::timeout` para definir um limite de tempo para os itens em um stream

Começamos adicionando um timeout ao stream com o método `timeout`, que vem da trait `StreamExt`. Em seguida, atualizamos o corpo do loop `while let`, porque o stream agora retorna um `Result`. A variante `Ok` indica que uma mensagem chegou a tempo; a variante `Err` indica que o timeout expirou antes que qualquer mensagem chegasse. Fazemos correspondência com esse resultado e imprimimos a mensagem quando a recebemos com sucesso ou imprimimos um aviso sobre o timeout. Finalmente, observe que fixamos as mensagens após aplicar o timeout a elas, porque o auxiliar de timeout produz um stream que precisa ser fixado para ser sondado.

No entanto, como não há atrasos entre as mensagens, esse timeout não altera o comportamento do programa. Vamos adicionar um atraso variável às mensagens que enviamos, como mostrado na Listagem 17-35.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::{pin::pin, time::Duration};

use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let mut messages =
            pin!(get_messages().timeout(Duration::from_millis(200)));

        while let Some(result) = messages.next().await {
            match result {
                Ok(message) => println!("{message}"),
                Err(reason) => eprintln!("Problema: {reason:?}"),
            }
        }
    })
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
        for (index, message) in messages.into_iter().enumerate() {
            let time_to_sleep = if index % 2 == 0 { 100 } else { 300 };
            trpl::sleep(Duration::from_millis(time_to_sleep)).await;

            tx.send(format!("Mensagem: '{message}'")).unwrap();
        }
    });

    ReceiverStream::new(rx)
}
```

Listagem 17-35: Enviando mensagens através de `tx` com um atraso assíncrono sem tornar `get_messages` uma função assíncrona

Em `get_messages`, usamos o método iterador `enumerate` com o array `messages` para que possamos obter o índice de cada item que estamos enviando junto com o próprio item. Em seguida, aplicamos um atraso de 100 milissegundos a itens de índice par e um atraso de 300 milissegundos a itens de índice ímpar para simular os diferentes atrasos que poderíamos ver de um stream de mensagens no mundo real. Como nosso timeout é de 200 milissegundos, isso deve afetar metade das mensagens.

Para dormir entre mensagens na função `get_messages` sem bloquear, precisamos usar async. No entanto, não podemos transformar o próprio `get_messages` em uma função assíncrona, porque então retornaríamos uma `Future<Output = Stream<Item = String>>` em vez de uma `Stream<Item = String>>`. O chamador teria que aguardar o próprio `get_messages` para ter acesso ao stream. Mas lembre-se: tudo em uma determinada future acontece linearmente; a concorrência acontece _entre_ futures. Aguardar `get_messages` exigiria que ele enviasse todas as mensagens, incluindo o atraso de sleep entre cada mensagem, antes de retornar o stream do receptor. Como resultado, o timeout seria inútil. Não haveria atrasos no próprio stream; todos aconteceriam antes que o stream estivesse disponível.

Em vez disso, deixamos `get_messages` como uma função regular que retorna um stream e geramos uma tarefa para lidar com as chamadas assíncronas `sleep`.

Nota: Chamar `spawn_task` desta forma funciona porque já configuramos nosso runtime; se não o tivéssemos feito, isso causaria um pânico. Outras implementações escolhem diferentes trade-offs: elas podem gerar um novo runtime e evitar o pânico, mas acabam com um pouco de sobrecarga extra, ou podem simplesmente não fornecer uma maneira independente de gerar tarefas sem referência a um runtime. Certifique-se de saber qual trade-off seu runtime escolheu e escreva seu código de acordo!

Agora nosso código tem um resultado muito mais interessante. Entre cada dois pares de mensagens, um erro `Problem: Elapsed(())`.

```
Mensagem: 'a'
Problema: Elapsed(())
Mensagem: 'b'
Mensagem: 'c'
Problema: Elapsed(())
Mensagem: 'd'
Mensagem: 'e'
Problema: Elapsed(())
Mensagem: 'f'
Mensagem: 'g'
Problema: Elapsed(())
Mensagem: 'h'
Mensagem: 'i'
Problema: Elapsed(())
Mensagem: 'j'
```

O timeout não impede que as mensagens cheguem no final. Ainda recebemos todas as mensagens originais, porque nosso canal é _ilimitado_: ele pode conter tantas mensagens quanto possamos caber na memória. Se a mensagem não chegar antes do timeout, nosso manipulador de stream levará isso em conta, mas quando ele sondar o stream novamente, a mensagem pode já ter chegado.

Você pode obter comportamentos diferentes, se necessário, usando outros tipos de canais ou outros tipos de streams de forma mais geral. Vamos ver um desses na prática combinando um stream de intervalos de tempo com este stream de mensagens.

## Mesclando Streams

Primeiro, vamos criar outro stream, que emitirá um item a cada milissegundo se o deixarmos executar diretamente. Para simplificar, podemos usar a função `sleep` para enviar uma mensagem com atraso e combiná-la com a mesma abordagem que usamos em `get_messages` de criar um stream a partir de um canal. A diferença é que desta vez, vamos enviar de volta a contagem de intervalos que se passaram, então o tipo de retorno será `impl Stream<Item = u32>`, e podemos chamar a função `get_intervals` (veja a Listagem 17-36).

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::{pin::pin, time::Duration};

use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let mut messages =
            pin!(get_messages().timeout(Duration::from_millis(200)));

        while let Some(result) = messages.next().await {
            match result {
                Ok(message) => println!("{message}"),
                Err(reason) => eprintln!("Problema: {reason:?}"),
            }
        }
    })
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
        for (index, message) in messages.into_iter().enumerate() {
            let time_to_sleep = if index % 2 == 0 { 100 } else { 300 };
            trpl::sleep(Duration::from_millis(time_to_sleep)).await;

            tx.send(format!("Mensagem: '{message}'")).unwrap();
        }
    });

    ReceiverStream::new(rx)
}

fn get_intervals() -> impl Stream<Item = u32> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let mut count = 0;
        loop {
            trpl::sleep(Duration::from_millis(1)).await;
            count += 1;
            tx.send(count).unwrap();
        }
    });

    ReceiverStream::new(rx)
}
```

Listagem 17-36: Criando um stream com um contador que será emitido uma vez a cada milissegundo

Começamos definindo um `count` na tarefa. (Poderíamos defini-lo fora da tarefa também, mas é mais claro limitar o escopo de qualquer variável dada.) Em seguida, criamos um loop infinito. Cada iteração do loop dorme assincronamente por um milissegundo, incrementa a contagem e depois a envia pelo canal. Como tudo isso está envolvido na tarefa criada por `spawn_task`, tudo isso — incluindo o loop infinito — será limpo junto com o runtime.

Esse tipo de loop infinito, que termina apenas quando todo o runtime é desmontado, é bastante comum em Rust assíncrono: muitos programas precisam continuar executando indefinidamente. Com async, isso não bloqueia mais nada, desde que haja pelo menos um ponto de await em cada iteração do loop.

Agora, de volta ao bloco assíncrono da nossa função principal, podemos tentar mesclar os streams `messages` e `intervals`, como mostrado na Listagem 17-37.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::{pin::pin, time::Duration};

use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let messages = get_messages().timeout(Duration::from_millis(200));
        let intervals = get_intervals();
        let merged = messages.merge(intervals);

        while let Some(result) = merged.next().await {
            match result {
                Ok(message) => println!("{message}"),
                Err(reason) => eprintln!("Problema: {reason:?}"),
            }
        }
    })
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
        for (index, message) in messages.into_iter().enumerate() {
            let time_to_sleep = if index % 2 == 0 { 100 } else { 300 };
            trpl::sleep(Duration::from_millis(time_to_sleep)).await;

            tx.send(format!("Mensagem: '{message}'")).unwrap();
        }
    });

    ReceiverStream::new(rx)
}

fn get_intervals() -> impl Stream<Item = u32> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let mut count = 0;
        loop {
            trpl::sleep(Duration::from_millis(1)).await;
            count += 1;
            tx.send(count).unwrap();
        }
    });

    ReceiverStream::new(rx)
}
```

Listagem 17-37: Tentando mesclar os streams `messages` e `intervals`

Começamos chamando `get_intervals`. Em seguida, mesclamos os streams `messages` e `intervals` com o método `merge`, que combina múltiplos streams em um único stream que produz itens de qualquer um dos streams de origem assim que os itens estiverem disponíveis, sem impor uma ordem específica. Finalmente, percorremos esse stream combinado em vez de percorrer `messages`.

Neste ponto, nem `messages` nem `intervals` precisam ser fixados ou mutáveis, porque ambos serão combinados no único stream `merged`. No entanto, esta chamada a `merge` não compila! (Nem a chamada `next` no loop `while let`, mas voltaremos a isso.) Isso ocorre porque os dois streams têm tipos diferentes. O stream `messages` tem o tipo `Timeout<impl Stream<Item = String>>`, onde `Timeout` é o tipo que implementa `Stream` para uma chamada `timeout`. O stream `intervals` tem o tipo `impl Stream<Item = u32>`. Para mesclar esses dois streams, precisamos transformar um deles para corresponder ao outro. Retrabalharemos o stream de intervalos, porque messages já está no formato básico que queremos e precisa lidar com erros de timeout (veja a Listagem 17-38).

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::{pin::pin, time::Duration};

use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let messages = get_messages().timeout(Duration::from_millis(200));
        let intervals = get_intervals()
            .map(|count| format!("Intervalo: {count}"))
            .timeout(Duration::from_secs(10));
        let merged = messages.merge(intervals);
        let mut stream = pin!(merged);

        while let Some(result) = stream.next().await {
            match result {
                Ok(message) => println!("{message}"),
                Err(reason) => eprintln!("Problema: {reason:?}"),
            }
        }
    })
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
        for (index, message) in messages.into_iter().enumerate() {
            let time_to_sleep = if index % 2 == 0 { 100 } else { 300 };
            trpl::sleep(Duration::from_millis(time_to_sleep)).await;

            tx.send(format!("Mensagem: '{message}'")).unwrap();
        }
    });

    ReceiverStream::new(rx)
}

fn get_intervals() -> impl Stream<Item = u32> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let mut count = 0;
        loop {
            trpl::sleep(Duration::from_millis(1)).await;
            count += 1;
            tx.send(count).unwrap();
        }
    });

    ReceiverStream::new(rx)
}
```

Listagem 17-38: Alinhando o tipo do stream `intervals` com o tipo do stream `messages`

Primeiro, podemos usar o método auxiliar `map` para transformar os `intervals` em uma string. Segundo, precisamos corresponder ao `Timeout` de `messages`. Como não queremos realmente um timeout para `intervals`, podemos apenas criar um timeout que seja mais longo que as outras durações que estamos usando. Aqui, criamos um timeout de 10 segundos com `Duration::from_secs(10)`. Finalmente, precisamos tornar `stream` mutável, para que as chamadas `next` do loop `while let` possam iterar pelo stream, e fixá-lo para que seja seguro fazê-lo. Isso nos aproxima _quase_ do que precisamos. Tudo verifica o tipo. Se você executar isso, porém, haverá dois problemas. Primeiro, nunca vai parar! Você precisará pará-lo com ctrl-c. Segundo, as mensagens do alfabeto inglês estarão enterradas no meio de todas as mensagens do contador de intervalos:

```
--snip--
Intervalo: 38
Intervalo: 39
Intervalo: 40
Mensagem: 'a'
Intervalo: 41
Intervalo: 42
Intervalo: 43
--snip--
```

A Listagem 17-39 mostra uma maneira de resolver estes dois últimos problemas.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::{pin::pin, time::Duration};

use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let messages = get_messages().timeout(Duration::from_millis(200));
        let intervals = get_intervals()
            .map(|count| format!("Intervalo: {count}"))
            .throttle(Duration::from_millis(100))
            .timeout(Duration::from_secs(10));
        let merged = messages.merge(intervals).take(20);
        let mut stream = pin!(merged);

        while let Some(result) = stream.next().await {
            match result {
                Ok(message) => println!("{message}"),
                Err(reason) => eprintln!("Problema: {reason:?}"),
            }
        }
    })
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
        for (index, message) in messages.into_iter().enumerate() {
            let time_to_sleep = if index % 2 == 0 { 100 } else { 300 };
            trpl::sleep(Duration::from_millis(time_to_sleep)).await;

            tx.send(format!("Mensagem: '{message}'")).unwrap();
        }
    });

    ReceiverStream::new(rx)
}

fn get_intervals() -> impl Stream<Item = u32> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let mut count = 0;
        loop {
            trpl::sleep(Duration::from_millis(1)).await;
            count += 1;
            tx.send(count).unwrap();
        }
    });

    ReceiverStream::new(rx)
}
```

Listagem 17-39: Usando `throttle` e `take` para gerenciar os streams mesclados

Primeiro, usamos o método `throttle` no stream `intervals` para que ele não sobrecarregue o stream `messages`. _Throttling_ é uma maneira de limitar a taxa na qual uma função será chamada — ou, neste caso, com que frequência o stream será sondado. Uma vez a cada 100 milissegundos deve ser suficiente, porque é aproximadamente com que frequência nossas mensagens chegam.

Para limitar o número de itens que aceitaremos de um stream, aplicamos o método `take` ao stream `merged`, porque queremos limitar a saída final, não apenas um stream ou outro.

Agora, quando executamos o programa, ele para após extrair 20 itens do stream, e os intervalos não sobrecarregam as mensagens. Também não obtemos `Intervalo: 100` ou `Intervalo: 200` e assim por diante, mas em vez disso obtemos `Intervalo: 1`, `Intervalo: 2` e assim por diante — mesmo que tenhamos um stream de origem que _pode_ produzir um evento a cada milissegundo. Isso ocorre porque a chamada `throttle` produz um novo stream que envolve o stream original para que o stream original seja sondado apenas na taxa de throttle, não em sua própria taxa "nativa". Não temos um monte de mensagens de intervalo não tratadas que estamos escolhendo ignorar. Em vez disso, nunca produzimos essas mensagens de intervalo em primeiro lugar! Esta é a "preguiça" inerente das futures do Rust em ação novamente, permitindo que escolhamos nossas características de desempenho.

```
Intervalo: 1
Mensagem: 'a'
Intervalo: 2
Intervalo: 3
Problema: Elapsed(())
Intervalo: 4
Mensagem: 'b'
Intervalo: 5
Mensagem: 'c'
Intervalo: 6
Intervalo: 7
Problema: Elapsed(())
Intervalo: 8
Mensagem: 'd'
Intervalo: 9
Mensagem: 'e'
Intervalo: 10
Intervalo: 11
Problema: Elapsed(())
Intervalo: 12
```

Há uma última coisa que precisamos tratar: erros! Com ambos esses streams baseados em canal, as chamadas `send` podem falhar quando o outro lado do canal for fechado — e isso é apenas uma questão de como o runtime executa as futures que compõem o stream. Até agora, ignoramos essa possibilidade chamando `unwrap`, mas em um aplicativo bem-comportado, devemos lidar explicitamente com o erro, no mínimo encerrando o loop para não tentarmos enviar mais mensagens. A Listagem 17-40 mostra uma estratégia de erro simples: imprimir o problema e depois usar `break` para sair dos loops.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::{pin::pin, time::Duration};

use trpl::{ReceiverStream, Stream, StreamExt};

fn main() {
    trpl::run(async {
        let messages = get_messages().timeout(Duration::from_millis(200));
        let intervals = get_intervals()
            .map(|count| format!("Intervalo #{count}"))
            .throttle(Duration::from_millis(500))
            .timeout(Duration::from_secs(10));
        let merged = messages.merge(intervals).take(20);
        let mut stream = pin!(merged);

        while let Some(result) = stream.next().await {
            match result {
                Ok(item) => println!("{item}"),
                Err(reason) => eprintln!("Problema: {reason:?}"),
            }
        }
    });
}

fn get_messages() -> impl Stream<Item = String> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];

        for (index, message) in messages.into_iter().enumerate() {
            let time_to_sleep = if index % 2 == 0 { 100 } else { 300 };
            trpl::sleep(Duration::from_millis(time_to_sleep)).await;

            if let Err(send_error) = tx.send(format!("Mensagem: '{message}'")) {
                eprintln!("Não foi possível enviar mensagem '{message}': {send_error}");
                break;
            }
        }
    });

    ReceiverStream::new(rx)
}

fn get_intervals() -> impl Stream<Item = u32> {
    let (tx, rx) = trpl::channel();

    trpl::spawn_task(async move {
        let mut count = 0;
        loop {
            trpl::sleep(Duration::from_millis(1)).await;
            count += 1;

            if let Err(send_error) = tx.send(count) {
                eprintln!("Não foi possível enviar intervalo {count}: {send_error}");
                break;
            };
        }
    });

    ReceiverStream::new(rx)
}
```

Listagem 17-40: Tratando erros e encerrando os loops

Como de costume, a forma correta de lidar com um erro de envio de mensagem varia; apenas certifique-se de ter uma estratégia.

Agora que vimos muito async na prática, vamos dar um passo atrás e explorar alguns dos detalhes de como `Future`, `Stream` e as outras traits-chave que o Rust usa para fazer async funcionar.

**17.5 Traits para Programação Assíncrona**

# Traits para Programação Assíncrona

Ao longo deste capítulo, mencionamos repetidamente que os blocos e funções async em Rust são compilados em tipos que implementam a trait `Future`. Também mencionamos que os streams implementam a trait `Stream`. Nesta seção, exploraremos essas traits mais detalhadamente.

## A Trait Future

A trait `Future` é o bloco de construção fundamental para código assíncrono em Rust. Em termos gerais, um tipo que implementa `Future` pode produzir um valor, mas esse valor pode não estar disponível imediatamente. A definição da trait `Future` na biblioteca padrão é assim:

```rust
pub trait Future {
    type Output;
    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;
}
```

Vamos examinar cada parte:

- `type Output`: Este é o tipo de valor que a future produzirá quando estiver pronta. Por exemplo, a future retornada de um bloco `async { 5 }` teria `type Output = i32`.

- `fn poll`: Este é o método que verifica se a future está pronta. Ele não bloqueia; em vez disso, retorna um valor `Poll` que indica se a future está pronta (`Ready`) ou não (`Pending`).

- `Pin<&mut Self>`: `Pin` é um tipo wrapper que impede que dados sejam movidos na memória. Isso é importante para futures que contêm referências a seus próprios dados, o que é comum em código assíncrono. Discutiremos `Pin` mais adiante.

- `Context<'_>`: Este é um objeto que carrega informações sobre como o runtime async deve gerenciar a future, incluindo um "waker" que pode ser usado para notificar o runtime quando algo mudou e a future deve ser verificada novamente.

A API primária para `Future` é o método `poll`. Quando chamamos `poll` em uma future, uma de duas coisas pode acontecer:

1. A future está _pronta_, nesse caso ela retorna `Poll::Ready(output)` onde `output` é do tipo `Self::Output`.
2. A future ainda não está pronta, nesse caso ela retorna `Poll::Pending`. Além disso, a future registra no runtime (via o `Context`) que o runtime deve chamar `poll` novamente quando certas condições forem atendidas.

Quando escrevemos código async de alto nível, normalmente não chamamos `poll` diretamente. Em vez disso, usamos a palavra-chave `await` ou funções como `block_on` que executam a future até a conclusão. Estas funções chamam `poll` repetidamente até que a future retorne `Poll::Ready`.

### Estruturas Geradas pelo Compilador

Quando escrevemos uma função async ou bloco async em Rust, o compilador gera uma estrutura para implementar a trait `Future`. Por exemplo, quando escrevemos:

```rust
async fn example(x: u32) -> u32 {
    let y = async_compute(x).await;
    y + 1
}
```

O compilador gera algo aproximadamente assim:

```rust
fn example(x: u32) -> impl Future<Output = u32> {
    struct ExampleFuture {
        state: State,
        x: u32,
        y: Option<u32>,
    }

    enum State {
        Start,
        AwaitingAsyncCompute { future: AsyncComputeFuture },
        Done,
    }

    impl Future for ExampleFuture {
        type Output = u32;

        fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<u32> {
            loop {
                match self.state {
                    State::Start => {
                        let future = async_compute(self.x);
                        self.state = State::AwaitingAsyncCompute { future };
                    }
                    State::AwaitingAsyncCompute { ref mut future } => {
                        if let Poll::Ready(y) = Pin::new(future).poll(cx) {
                            self.y = Some(y);
                            self.state = State::Done;
                        } else {
                            return Poll::Pending;
                        }
                    }
                    State::Done => {
                        let y = self.y.take().unwrap();
                        return Poll::Ready(y + 1);
                    }
                }
            }
        }
    }

    ExampleFuture {
        state: State::Start,
        x,
        y: None,
    }
}
```

Note como o compilador cria uma máquina de estados para rastrear onde o código está no processo de execução. Quando a future é criada, ela começa no estado `Start`. Quando `poll` é chamado, ela progride através dos estados até que a computation esteja completa.

Este exemplo é bastante simplificado. O código gerado pelo compilador real para funções assíncronas é mais complexo, especialmente quando há loops, condicionais ou tratamento de erros envolvido. No entanto, a ideia básica é a mesma: o compilador cria uma máquina de estados onde cada ponto `await` corresponde a uma transição de estado.

## Pin e Unpin

Como vimos anteriormente no capítulo, lidamos com tipos `Pin` algumas vezes. `Pin` é uma feature crucial para futures seguras e eficientes em Rust. Aqui está um olhar mais detalhado em por que `Pin` é necessário e como ele funciona.

### Por que precisamos de Pin?

A trait `Future` em Rust permite que o progresso de uma operação assíncrona seja pausado e retomado. Quando uma future é pausada (retorna `Poll::Pending`), o estado atual da operação precisa ser armazenado para que possa ser retomado posteriormente. Na implementação gerada pelo compilador, este estado é armazenado em campos da estrutura da future.

No entanto, há um problema com futures que contêm referências a seus próprios campos. Se uma future pudesse ser movida livremente na memória, essas auto-referências poderiam se tornar inválidas. Por exemplo:

```rust
async {
    let mut x = [1, 2, 3];
    let ptr = &mut x[0] as *mut i32;
    some_async_function().await;
    *ptr += 1; // Perigoso se a future foi movida!
}
```

Aqui, temos um ponteiro `ptr` que aponta para uma localização dentro da variável `x`. Se esta future fosse movida para outro local na memória após o `await` mas antes de usar `ptr`, `ptr` não seria mais válido porque apontaria para a localização antiga de `x`.

Para evitar isso, Rust usa `Pin` para garantir que futures que contêm auto-referências não sejam movidas após serem fixadas.

### Como Pin funciona

`Pin<P>` é um tipo wrapper que encapsula outro tipo `P` (geralmente um ponteiro como `&mut T` ou `Box<T>`). A principal garantia que `Pin` fornece é que o valor apontado por `P` não será movido na memória depois que `Pin<P>` é criado, desde que o tipo subjacente não implemente `Unpin`.

A trait `Unpin` é uma trait "marcador" automática que a maioria dos tipos em Rust implementa. Um tipo que implementa `Unpin` pode ser movido livremente mesmo quando fixado. Para tipos que _não_ implementam `Unpin` (como a maioria das futures geradas pelo compilador), ser fixado significa que eles não podem ser movidos.

Isso é crucial para futures auto-referenciadas, porque garante que quaisquer ponteiros internos permaneçam válidos.

### Usando Pin

Para usar `Pin` com uma future, normalmente usamos uma das seguintes abordagens:

1. **`Box::pin`**: Para futures que precisam escapar para um contexto com tempo de vida desconhecido, podemos usar `Box::pin(my_future)` para colocar a future no heap e fixá-la lá.

2. **A macro `pin!`**: Para futures que estão restritas a um único escopo, podemos usar a macro `pin!` da biblioteca `std::pin` para criar uma referência fixada no stack.

3. **Tipos de ponteiro fixáveis**: Podemos criar manualmente um `Pin<&mut T>` ou `Pin<Box<T>>` a partir de um `&mut T` ou `Box<T>`, respectivamente, desde que garantamos que o valor não será mais movido.

Na maioria dos casos de alto nível, não precisamos lidar diretamente com `Pin`. Os runtimes assíncronos e combinadores de futures tratam disso para nós. Mas quando criamos nossas próprias abstrações de baixo nível, entender `Pin` é essencial.

## A Trait Stream

Na seção "Streams: Futures em Sequência", apresentamos a trait `Stream` como a contrapartida assíncrona da trait `Iterator`. Aqui está como ela é definida:

```rust
pub trait Stream {
    type Item;
    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>>;
}
```

A trait `Stream` é muito semelhante à trait `Future`, mas em vez de produzir um único valor, ela produz uma sequência de valores ao longo do tempo:

- `type Item`: Este é o tipo dos valores produzidos pelo stream.

- `fn poll_next`: Este método verifica se o próximo item no stream está disponível. Se estiver, ele retorna `Poll::Ready(Some(item))`. Se o stream terminou, ele retorna `Poll::Ready(None)`. Se o próximo item ainda não está disponível, ele retorna `Poll::Pending` e registra um waker, assim como `Future::poll`.

Assim como com `Future`, não costumamos chamar `poll_next` diretamente. Em vez disso, usamos métodos de alto nível como `next().await` ou combinadores de streams, que chamam `poll_next` conforme necessário.

### StreamExt

Como mencionamos, a trait `StreamExt` fornece métodos utilitários para `Stream`, assim como a trait `Iterator` fornece métodos para iteração síncrona. Aqui estão alguns dos métodos mais comuns:

- `next`: Retorna uma future que resolverá para `Option<Item>`, onde `None` indica que o stream terminou.
- `map`: Transforma os itens do stream usando uma função.
- `filter`: Filtra os itens do stream usando um predicado.
- `take`: Limita o stream a um número específico de itens.
- `merge`: Combina dois streams em um único stream que produz itens de qualquer um dos streams de origem.
- `timeout`: Adiciona um timeout a cada item do stream.
- `throttle`: Limita a taxa na qual os itens são produzidos.

Esses métodos são semelhantes aos fornecidos pela trait `Iterator`, mas adaptados para o contexto assíncrono.

## Outras Traits Importantes

Além de `Future` e `Stream`, existem várias outras traits importantes para programação assíncrona em Rust:

### Sink

A trait `Sink` é a contraparte do `Stream` para consumir itens assincronamente, em vez de produzi-los. Um `Sink` pode receber valores ao longo do tempo e processá-los de forma assíncrona:

```rust
pub trait Sink<Item> {
    type Error;
    fn poll_ready(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<(), Self::Error>>;
    fn start_send(
        self: Pin<&mut Self>,
        item: Item,
    ) -> Result<(), Self::Error>;
    fn poll_flush(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<(), Self::Error>>;
    fn poll_close(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<(), Self::Error>>;
}
```

- `poll_ready`: Verifica se o sink está pronto para receber um novo item.
- `start_send`: Envia um item para o sink.
- `poll_flush`: Tenta garantir que todos os itens enviados anteriormente sejam processados.
- `poll_close`: Fecha o sink, indicando que nenhum item mais será enviado.

### AsyncRead e AsyncWrite

As traits `AsyncRead` e `AsyncWrite` são contrapartes assíncronas das traits `Read` e `Write` da biblioteca padrão, permitindo operações de I/O que não bloqueiam o thread atual:

```rust
pub trait AsyncRead {
    fn poll_read(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
        buf: &mut [u8],
    ) -> Poll<Result<usize, Error>>;
}

pub trait AsyncWrite {
    fn poll_write(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
        buf: &[u8],
    ) -> Poll<Result<usize, Error>>;

    fn poll_flush(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<(), Error>>;

    fn poll_close(
        self: Pin<&mut Self>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<(), Error>>;
}
```

Essas traits permitem ler e escrever dados assincronamente, o que é crucial para operações de I/O eficientes em código assíncrono.

## O Ecossistema Async em Rust

O ecossistema assíncrono em Rust é construído sobre essas traits fundamentais, mas existem muitas crates e ferramentas que fornecem abstrações e implementações específicas:

### Runtimes Async

Os runtimes assíncronos em Rust são responsáveis por executar futures, gerenciar I/O assíncrono e fornecer APIs de alto nível para tarefas comuns:

- **Tokio**: Um runtime popular com foco em confiabilidade, produtividade e desempenho.
- **async-std**: Um runtime que visa ser semelhante à biblioteca padrão, mas com versões assíncronas das APIs.
- **smol**: Um runtime leve e simples para operações assíncronas.

### Crates para Trabalhar com Async

- **futures**: Fornece traits, funções e tipos para trabalhar com código assíncrono.
- **async-trait**: Permite definir métodos assíncronos em traits.
- **pin-project**: Fornece macros para trabalhar com `Pin` de forma segura.
- **crossbeam**: Oferece estruturas de dados concorrentes que podem ser usadas em código assíncrono.

As diferenças entre essas opções geralmente envolvem trocas entre desempenho, recursos e complexidade. Ao escolher componentes para um aplicativo assíncrono, leve em consideração seus requisitos específicos e as características de cada ferramenta.

## Resumo

Neste capítulo, exploramos a programação assíncrona em Rust, aprendendo sobre futures, streams e como combiná-los para realizar tarefas concorrentes sem as despesas gerais das threads tradicionais.

Começamos com um exemplo simples de um scraper web que utiliza as palavras-chave `async` e `await` para buscar e processar páginas web de forma concorrente. Vimos como as futures são "preguiçosas" em Rust e só fazem progresso quando são explicitamente aguardadas.

Em seguida, aplicamos concorrência com async para resolver os mesmos desafios que abordamos com threads no capítulo anterior. Aprendemos a criar novas tarefas assíncronas, a comunicar entre elas usando canais e a gerenciar sua execução.

Expandimos nosso conhecimento para trabalhar com qualquer número de futures usando ferramentas como `join_all` e lidando com os desafios associados a tipos e fixação (pinning). Também exploramos como competir futures uma contra a outra e como lidar com operações vinculadas à CPU em um contexto assíncrono.

Finalmente, mergulhamos no mundo dos streams, que são como iteradores assíncronos que produzem valores ao longo do tempo. Aprendemos a criar, transformar e combinar streams, e a lidar com operações comuns como timeouts, throttling e tratamento de erros.

Ao longo do caminho, também vimos como a programação assíncrona em Rust é construída sobre traits fundamentais como `Future`, `Stream`, `Pin` e `Unpin`, que fornecem as bases para código concorrente seguro e eficiente.

A programação assíncrona em Rust oferece um modelo poderoso para escrever código concorrente de alto desempenho com garantias de segurança em tempo de compilação. Ao entender os conceitos fundamentais apresentados neste capítulo, você está bem equipado para criar aplicativos Rust que aproveitam eficientemente os recursos do sistema enquanto mantêm a robustez e a segurança que o Rust é conhecido por fornecer.
