# Aplicando Concorrência com Async

Nesta seção, aplicaremos async aos mesmos desafios de concorrência que abordamos com threads no capítulo 16. Como já discutimos muitas das ideias principais lá, nesta seção vamos nos concentrar no que é diferente entre threads e futures.

Em muitos casos, as APIs para trabalhar com concorrência usando async são muito semelhantes às de uso de threads. Em outros casos, elas acabam sendo bastante diferentes. Mesmo quando as APIs _parecem_ semelhantes entre threads e async, elas frequentemente têm comportamentos diferentes - e quase sempre têm características de desempenho diferentes.

## Criando uma Nova Tarefa com `spawn_task`

A primeira operação que abordamos em "Criando uma Nova Thread com Spawn" foi contar em duas threads separadas. Vamos fazer o mesmo usando async. O crate `trpl` fornece uma função `spawn_task` que se parece muito com a API `thread::spawn`, e uma função `sleep` que é uma versão async da API `thread::sleep`. Podemos usar essas funções juntas para implementar o exemplo de contagem, como mostrado na Listagem 17-6.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        trpl::spawn_task(async {
            for i in 1..10 {
                println!("olá número {i} da primeira tarefa!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        });

        for i in 1..5 {
            println!("olá número {i} da segunda tarefa!");
            trpl::sleep(Duration::from_millis(500)).await;
        }
    });
}
```

Listagem 17-6: Criando uma nova tarefa para imprimir uma coisa enquanto a tarefa principal imprime outra

Como nosso ponto de partida, configuramos nossa função `main` com `trpl::run` para que nossa função de nível superior possa ser assíncrona.

> Nota: A partir deste ponto em diante no capítulo, cada exemplo incluirá exatamente o mesmo código de encapsulamento com `trpl::run` em `main`, então frequentemente pularemos isso assim como fazemos com `main`. Não se esqueça de incluí-lo em seu código!

Em seguida, escrevemos dois loops dentro desse bloco, cada um contendo uma chamada `trpl::sleep`, que espera meio segundo (500 milissegundos) antes de enviar a próxima mensagem. Colocamos um loop no corpo de um `trpl::spawn_task` e o outro em um loop `for` de nível superior. Também adicionamos um `await` após as chamadas `sleep`.

Este código se comporta de maneira semelhante à implementação baseada em threads - incluindo o fato de que você pode ver as mensagens aparecerem em uma ordem diferente em seu próprio terminal quando o executar:

```
olá número 1 da segunda tarefa!
olá número 1 da primeira tarefa!
olá número 2 da primeira tarefa!
olá número 2 da segunda tarefa!
olá número 3 da primeira tarefa!
olá número 3 da segunda tarefa!
olá número 4 da primeira tarefa!
olá número 4 da segunda tarefa!
olá número 5 da primeira tarefa!
```

Esta versão para assim que o loop `for` no corpo do bloco async principal termina, porque a tarefa gerada por `spawn_task` é encerrada quando a função `main` termina. Se você quiser que ela seja executada até a conclusão da tarefa, você precisará usar um manipulador de junção para esperar a primeira tarefa completar. Com threads, usamos o método `join` para "bloquear" até que a thread terminasse de executar. Na Listagem 17-7, podemos usar `await` para fazer a mesma coisa, porque o próprio manipulador de tarefa é uma future. Seu tipo `Output` é um `Result`, então também usamos unwrap após aguardá-lo.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let handle = trpl::spawn_task(async {
            for i in 1..10 {
                println!("olá número {i} da primeira tarefa!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        });

        for i in 1..5 {
            println!("olá número {i} da segunda tarefa!");
            trpl::sleep(Duration::from_millis(500)).await;
        }

        handle.await.unwrap();
    });
}
```

Listagem 17-7: Usando `await` com um manipulador de junção para executar uma tarefa até a conclusão

Esta versão atualizada é executada até que _ambos_ os loops terminem.

```
olá número 1 da segunda tarefa!
olá número 1 da primeira tarefa!
olá número 2 da primeira tarefa!
olá número 2 da segunda tarefa!
olá número 3 da primeira tarefa!
olá número 3 da segunda tarefa!
olá número 4 da primeira tarefa!
olá número 4 da segunda tarefa!
olá número 5 da primeira tarefa!
olá número 6 da primeira tarefa!
olá número 7 da primeira tarefa!
olá número 8 da primeira tarefa!
olá número 9 da primeira tarefa!
```

Até agora, parece que async e threads nos dão os mesmos resultados básicos, apenas com sintaxe diferente: usando `await` em vez de chamar `join` no manipulador de junção, e aguardando as chamadas `sleep`.

A maior diferença é que não precisamos criar outra thread do sistema operacional para fazer isso. Na verdade, nem precisamos criar uma tarefa aqui. Como blocos async compilam para futures anônimas, podemos colocar cada loop em um bloco async e fazer o runtime executar ambos até a conclusão usando a função `trpl::join`.

Na seção "Esperando que Todas as Threads Terminem Usando Manipuladores `join`", mostramos como usar o método `join` no tipo `JoinHandle` retornado quando você chama `std::thread::spawn`. A função `trpl::join` é semelhante, mas para futures. Quando você dá a ela duas futures, ela produz uma única nova future cuja saída é uma tupla contendo a saída de cada future que você passou quando _ambas_ completarem. Assim, na Listagem 17-8, usamos `trpl::join` para esperar que tanto `fut1` quanto `fut2` terminem. Nós _não_ aguardamos `fut1` e `fut2`, mas sim a nova future produzida por `trpl::join`. Ignoramos a saída, porque é apenas uma tupla contendo dois valores unitários.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let fut1 = async {
            for i in 1..10 {
                println!("olá número {i} da primeira tarefa!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        };

        let fut2 = async {
            for i in 1..5 {
                println!("olá número {i} da segunda tarefa!");
                trpl::sleep(Duration::from_millis(500)).await;
            }
        };

        trpl::join(fut1, fut2).await;
    });
}
```

Listagem 17-8: Usando `trpl::join` para aguardar duas futures anônimas

Quando executamos isso, vemos ambas as futures sendo executadas até a conclusão:

```
olá número 1 da primeira tarefa!
olá número 1 da segunda tarefa!
olá número 2 da primeira tarefa!
olá número 2 da segunda tarefa!
olá número 3 da primeira tarefa!
olá número 3 da segunda tarefa!
olá número 4 da primeira tarefa!
olá número 4 da segunda tarefa!
olá número 5 da primeira tarefa!
olá número 6 da primeira tarefa!
olá número 7 da primeira tarefa!
olá número 8 da primeira tarefa!
olá número 9 da primeira tarefa!
```

Agora, você verá exatamente a mesma ordem toda vez, o que é muito diferente do que vimos com threads. Isso ocorre porque a função `trpl::join` é _justa_, o que significa que ela verifica cada future com a mesma frequência, alternando entre elas, e nunca deixa uma correr à frente se a outra estiver pronta. Com threads, o sistema operacional decide qual thread verificar e por quanto tempo deixá-la executar. Com Rust assíncrono, o runtime decide qual tarefa verificar. (Na prática, os detalhes ficam complicados porque um runtime assíncrono pode usar threads do sistema operacional sob o capô como parte de como gerencia a concorrência, então garantir justiça pode ser mais trabalho para um runtime - mas ainda é possível!) Os runtimes não precisam garantir justiça para qualquer operação específica, e frequentemente oferecem diferentes APIs para permitir que você escolha se deseja ou não justiça.

Experimente algumas dessas variações ao aguardar as futures e veja o que elas fazem:
- Remova o bloco async de um ou ambos os loops.
- Aguarde cada bloco async imediatamente após defini-lo.
- Envolva apenas o primeiro loop em um bloco async e aguarde a future resultante após o corpo do segundo loop.

Para um desafio extra, veja se você consegue descobrir qual será a saída em cada caso _antes_ de executar o código!

## Contando em Duas Tarefas Usando Passagem de Mensagens

Compartilhar dados entre futures também será familiar: usaremos passagem de mensagens novamente, mas desta vez com versões assíncronas dos tipos e funções. Vamos seguir um caminho ligeiramente diferente do que fizemos em "Usando Passagem de Mensagens para Transferir Dados Entre Threads" para ilustrar algumas das principais diferenças entre concorrência baseada em threads e baseada em futures. Na Listagem 17-9, começaremos com apenas um único bloco async - _não_ criando uma tarefa separada como criamos uma thread separada.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let val = String::from("oi");
        tx.send(val).unwrap();

        let received = rx.recv().await.unwrap();
        println!("Recebido: {received}");
    });
}
```

Listagem 17-9: Criando um canal assíncrono e atribuindo as duas metades a `tx` e `rx`

Aqui, usamos `trpl::channel`, uma versão assíncrona da API de canal de múltiplos produtores, único consumidor que usamos com threads no Capítulo 16. A versão assíncrona da API é apenas um pouco diferente da versão baseada em threads: ela usa um receptor mutável `rx` em vez de imutável, e seu método `recv` produz uma future que precisamos aguardar em vez de produzir o valor diretamente. Agora podemos enviar mensagens do remetente para o receptor. Observe que não precisamos criar uma thread separada ou mesmo uma tarefa; apenas precisamos aguardar a chamada `rx.recv`.

O método síncrono `Receiver::recv` em `std::mpsc::channel` bloqueia até receber uma mensagem. O método `trpl::Receiver::recv` não o faz, porque é assíncrono. Em vez de bloquear, ele devolve o controle ao runtime até que uma mensagem seja recebida ou o lado de envio do canal seja fechado. Por outro lado, não aguardamos a chamada `send`, porque ela não bloqueia. Não precisa, porque o canal para o qual estamos enviando é ilimitado.

> Nota: Como todo esse código assíncrono é executado em um bloco async em uma chamada `trpl::run`, tudo dentro dele pode evitar o bloqueio. No entanto, o código _fora_ dele bloqueará na função `run` retornando. Esse é o ponto principal da função `trpl::run`: ela permite que você _escolha_ onde bloquear em algum conjunto de código assíncrono, e assim onde fazer a transição entre código síncrono e assíncrono. Na maioria dos runtimes assíncronos, `run` é realmente chamado de `block_on` exatamente por esse motivo.

Observe duas coisas sobre este exemplo. Primeiro, a mensagem chegará imediatamente. Segundo, embora usemos uma future aqui, ainda não há concorrência. Tudo na listagem acontece em sequência, assim como seria se não houvesse futures envolvidas.

Vamos abordar a primeira parte enviando uma série de mensagens e dormindo entre elas, como mostrado na Listagem 17-10.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let vals = vec![
            String::from("oi"),
            String::from("do"),
            String::from("futuro"),
            String::from("distante"),
        ];

        for val in vals {
            tx.send(val).unwrap();
            trpl::sleep(Duration::from_millis(500)).await;
        }

        while let Some(value) = rx.recv().await {
            println!("recebido '{value}'");
        }
    });
}
```

Listagem 17-10: Enviando e recebendo múltiplas mensagens pelo canal assíncrono e dormindo com um `await` entre cada mensagem

Além de enviar as mensagens, precisamos recebê-las. Neste caso, como sabemos quantas mensagens estão chegando, poderíamos fazer isso manualmente chamando `rx.recv().await` quatro vezes. No mundo real, porém, geralmente estaremos esperando por um _número desconhecido_ de mensagens, então precisamos continuar esperando até determinarmos que não há mais mensagens.

Na Listagem 16-10, usamos um loop `for` para processar todos os itens recebidos de um canal síncrono. No entanto, o Rust ainda não tem uma maneira de escrever um loop `for` sobre uma série _assíncrona_ de itens, então precisamos usar um loop que não vimos antes: o loop condicional `while let`. Esta é a versão em loop da construção `if let` que vimos na seção "Fluxo de Controle Conciso com `if let` e `let else`". O loop continuará executando enquanto o padrão que ele especifica continuar a corresponder ao valor.

A chamada `rx.recv` produz uma future, que aguardamos. O runtime pausará a future até que ela esteja pronta. Quando uma mensagem chega, a future será resolvida para `Some(message)` tantas vezes quanto uma mensagem chegar. Quando o canal é fechado, independentemente de _quaisquer_ mensagens terem chegado, a future será resolvida para `None` para indicar que não há mais valores e, portanto, devemos parar de sondar - ou seja, parar de aguardar.

O loop `while let` reúne tudo isso. Se o resultado da chamada `rx.recv().await` for `Some(message)`, teremos acesso à mensagem e poderemos usá-la no corpo do loop, assim como poderíamos com `if let`. Se o resultado for `None`, o loop termina. Cada vez que o loop é concluído, ele atinge o ponto de espera novamente, então o runtime o pausa novamente até que outra mensagem chegue.

O código agora envia e recebe com sucesso todas as mensagens. Infelizmente, ainda existem alguns problemas. Por um lado, as mensagens não chegam em intervalos de meio segundo. Elas chegam todas de uma vez, 2 segundos (2.000 milissegundos) após iniciarmos o programa. Por outro lado, este programa também nunca termina! Em vez disso, ele espera para sempre por novas mensagens. Você precisará encerrá-lo usando ctrl-c.

Vamos começar examinando por que as mensagens chegam todas de uma vez após o atraso completo, em vez de chegarem com atrasos entre cada uma. Dentro de um determinado bloco async, a ordem em que as palavras-chave `await` aparecem no código também é a ordem em que elas são executadas quando o programa é executado.

Há apenas um bloco async na Listagem 17-10, então tudo nele é executado linearmente. Ainda não há concorrência. Todas as chamadas `tx.send` acontecem, intercaladas com todas as chamadas `trpl::sleep` e seus pontos de espera associados. Só então o loop `while let` pode passar por qualquer um dos pontos `await` nas chamadas `recv`.

Para obter o comportamento que queremos, onde o atraso de sleep acontece entre cada mensagem, precisamos colocar as operações `tx` e `rx` em seus próprios blocos async, como mostrado na Listagem 17-11. Então o runtime pode executar cada um deles separadamente usando `trpl::join`, assim como no exemplo de contagem. Mais uma vez, aguardamos o resultado da chamada `trpl::join`, não as futures individuais. Se aguardássemos as futures individuais em sequência, acabaríamos voltando a um fluxo sequencial - exatamente o que estamos tentando _não_ fazer.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx_fut = async {
            let vals = vec![
                String::from("oi"),
                String::from("do"),
                String::from("futuro"),
                String::from("distante"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_millis(500)).await;
            }
        };

        let rx_fut = async {
            while let Some(value) = rx.recv().await {
                println!("recebido '{value}'");
            }
        };

        trpl::join(tx_fut, rx_fut).await;
    });
}
```

Listagem 17-11: Separando `send` e `recv` em seus próprios blocos `async` e aguardando as futures para esses blocos

Com o código atualizado na Listagem 17-11, as mensagens são impressas em intervalos de 500 milissegundos, em vez de todas de uma vez após 2 segundos.

No entanto, o programa ainda nunca termina, devido à forma como o loop `while let` interage com `trpl::join`:
- A future retornada de `trpl::join` completa apenas quando _ambas_ as futures passadas para ela tiverem completado.
- A future `tx` completa uma vez que termina de dormir após enviar a última mensagem em `vals`.
- A future `rx` não completará até que o loop `while let` termine.
- O loop `while let` não terminará até que aguardar `rx.recv` produza `None`.
- Aguardar `rx.recv` retornará `None` apenas quando o outro lado do canal estiver fechado.
- O canal fechará apenas se chamarmos `rx.close` ou quando o lado do remetente, `tx`, for descartado.
- Não chamamos `rx.close` em nenhum lugar, e `tx` não será descartado até que o bloco async mais externo passado para `trpl::run` termine.
- O bloco não pode terminar porque está bloqueado na conclusão de `trpl::join`, o que nos leva de volta ao topo desta lista.

Poderíamos fechar manualmente `rx` chamando `rx.close` em algum lugar, mas isso não faz muito sentido. Parar após lidar com um número arbitrário de mensagens faria o programa desligar, mas poderíamos perder mensagens. Precisamos de outra maneira de garantir que `tx` seja descartado _antes_ do final da função.

No momento, o bloco async onde enviamos as mensagens apenas empresta `tx` porque enviar uma mensagem não requer propriedade, mas se pudéssemos mover `tx` para esse bloco async, ele seria descartado assim que esse bloco terminasse. Na seção "Capturando Referências ou Movendo a Propriedade" do Capítulo 13, você aprendeu como usar a palavra-chave `move` com closures, e, como discutido na seção "Usando Closures `move` com Threads" do Capítulo 16, frequentemente precisamos mover dados para closures quando trabalhamos com threads. A mesma dinâmica básica se aplica a blocos async, então a palavra-chave `move` funciona com blocos async assim como funciona com closures.

Na Listagem 17-12, mudamos o bloco usado para enviar mensagens de `async` para `async move`. Quando executamos _esta_ versão do código, ele desliga graciosamente após a última mensagem ser enviada e recebida.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx_fut = async move {
            let vals = vec![
                String::from("oi"),
                String::from("do"),
                String::from("futuro"),
                String::from("distante"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_millis(500)).await;
            }
        };

        let rx_fut = async {
            while let Some(value) = rx.recv().await {
                println!("recebido '{value}'");
            }
        };

        trpl::join(tx_fut, rx_fut).await;
    });
}
```

Listagem 17-12: Uma revisão do código da Listagem 17-11 que desliga corretamente quando completo

Este canal assíncrono também é um canal de múltiplos produtores, então podemos chamar `clone` em `tx` se quisermos enviar mensagens de múltiplas futures, como mostrado na Listagem 17-13.

Nome do arquivo: src/main.rs

```rust
extern crate trpl; // necessário para mdbook test

use std::time::Duration;

fn main() {
    trpl::run(async {
        let (tx, mut rx) = trpl::channel();

        let tx1 = tx.clone();
        let tx1_fut = async move {
            let vals = vec![
                String::from("oi"),
                String::from("do"),
                String::from("futuro"),
                String::from("distante"),
            ];

            for val in vals {
                tx1.send(val).unwrap();
                trpl::sleep(Duration::from_millis(500)).await;
            }
        };

        let rx_fut = async {
            while let Some(value) = rx.recv().await {
                println!("recebido '{value}'");
            }
        };

        let tx_fut = async move {
            let vals = vec![
                String::from("mais"),
                String::from("mensagens"),
                String::from("para"),
                String::from("você"),
            ];

            for val in vals {
                tx.send(val).unwrap();
                trpl::sleep(Duration::from_millis(1500)).await;
            }
        };

        trpl::join3(tx1_fut, tx_fut, rx_fut).await;
    });
}
```

Listagem 17-13: Usando múltiplos produtores com blocos async

Primeiro, clonamos `tx`, criando `tx1` fora do primeiro bloco async. Movemos `tx1` para esse bloco assim como fizemos antes com `tx`. Em seguida, mais tarde, movemos o `tx` original para um _novo_ bloco async, onde enviamos mais mensagens com um atraso ligeiramente mais lento. Colocamos este novo bloco async após o bloco async para receber mensagens, mas ele poderia vir antes também. A chave é a ordem em que as futures são aguardadas, não a ordem em que são criadas.

Ambos os blocos async para enviar mensagens precisam ser blocos `async move` para que tanto `tx` quanto `tx1` sejam descartados quando esses blocos terminarem. Caso contrário, acabaríamos voltando ao mesmo loop infinito com que começamos. Finalmente, mudamos de `trpl::join` para `trpl::join3` para lidar com a future adicional.

Agora vemos todas as mensagens de ambas as futures de envio, e como as futures de envio usam atrasos ligeiramente diferentes após o envio, as mensagens também são recebidas nesses diferentes intervalos.

```
recebido 'oi'
recebido 'mais'
recebido 'do'
recebido 'futuro'
recebido 'mensagens'
recebido 'distante'
recebido 'para'
recebido 'você'
```

Este é um bom começo, mas nos limita a apenas um punhado de futures: duas com `join`, ou três com `join3`. Vamos ver como poderíamos trabalhar com mais futures.