# Encerramento Gracioso e Limpeza (Graceful Shutdown and Cleanup)

O código na Listagem 21-20 está respondendo a requisições de forma assíncrona através do uso de um *thread pool*, como pretendíamos. Recebemos alguns avisos sobre os campos `workers`, `id` e `thread` que não estamos usando de forma direta, o que nos lembra que não estamos limpando nada. Quando usamos o método menos elegante `ctrl-c` para interromper a *thread* principal, todas as outras *threads* são interrompidas imediatamente também, mesmo que estejam no meio do atendimento de uma requisição.

Em seguida, implementaremos o *trait* `Drop` para chamar `join` em cada uma das *threads* no *pool*, para que elas possam terminar as requisições em que estão trabalhando antes de fechar. Depois, implementaremos uma maneira de dizer às *threads* que elas devem parar de aceitar novas requisições e encerrar. Para ver este código em ação, modificaremos nosso servidor para aceitar apenas duas requisições antes de encerrar graciosamente seu *thread pool*.

Uma coisa a notar à medida que avançamos: nada disso afeta as partes do código que lidam com a execução das *closures*, então tudo aqui seria exatamente o mesmo se estivéssemos usando um *thread pool* para um *runtime* assíncrono.

## Implementando o Trait `Drop` em `ThreadPool`

Vamos começar implementando `Drop` em nosso *thread pool*. Quando o *pool* for descartado, nossas *threads* devem todas fazer *join* para garantir que terminem seu trabalho. A Listagem 21-22 mostra uma primeira tentativa de implementação de `Drop`; este código ainda não funcionará completamente.

*Arquivo: src/lib.rs*

```rust
use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: mpsc::Sender<Job>,
}

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    /// Cria um novo ThreadPool.
    ///
    /// O tamanho é o número de threads no pool.
    ///
    /// # Panics
    ///
    /// A função `new` entrará em pânico se o tamanho for zero.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool { workers, sender }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        for worker in &mut self.workers {
            println!("Desligando worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {id} recebeu um trabalho; executando.");

            job();
        });

        Worker { id, thread }
    }
}

```
*Listagem 21-22: Fazendo join em cada thread quando o thread pool sai de escopo*

Primeiro, iteramos por cada um dos `workers` do *thread pool*. Usamos `&mut` para isso porque `self` é uma referência mutável, e também precisamos ser capazes de mutar `worker`. Para cada *worker*, imprimimos uma mensagem dizendo que este *worker* em particular está sendo desligado e, em seguida, chamamos `join` na *thread* desse *worker*. Se a chamada para `join` falhar, usamos `unwrap` para fazer o Rust entrar em pânico e ir para um desligamento não gracioso.

Aqui está o erro que obtemos quando compilamos este código:

```text
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0507]: cannot move out of `worker.thread` which is behind a mutable reference
    --> src/lib.rs:52:13
     |
52   |             worker.thread.join().unwrap();
     |             ^^^^^^^^^^^^^ ------ `worker.thread` moved due to this method call
     |             |
     |             move occurs because `worker.thread` has type `JoinHandle<()>`, which does not implement the `Copy` trait
     |
note: `JoinHandle::<T>::join` takes ownership of the receiver `self`, which moves `worker.thread`
    --> file:///home/.rustup/toolchains/1.82/lib/rustlib/src/rust/library/std/src/thread/mod.rs:1763:17
     |
1763 |     pub fn join(self) -> Result<T> {
     |                 ^^^^

For more information about this error, try `rustc --explain E0507`.
error: could not compile `hello` (lib) due to 1 previous error

```

O erro nos diz que não podemos chamar `join` porque temos apenas um empréstimo mutável de cada `worker` e `join` assume a propriedade de seu argumento.  Para resolver esse problema, precisamos mover a *thread* para fora da instância `Worker` que possui `thread` para que `join` possa consumir a *thread*. Uma maneira de fazer isso é adotando a mesma abordagem que fizemos na Listagem 18-15. Se `Worker` contivesse um `Option<thread::JoinHandle<()>>`, poderíamos chamar o método `take` no `Option` para mover o valor para fora da variante `Some` e deixar uma variante `None` em seu lugar. Em outras palavras, um `Worker` que está executando teria uma variante `Some` em `thread`, e quando quiséssemos limpar um `Worker`, substituiríamos `Some` por `None` para que o `Worker` não tivesse uma *thread* para executar.

No entanto, a *única* vez que isso aconteceria seria ao descartar o `Worker`. Em troca, teríamos que lidar com um `Option<thread::JoinHandle<()>>` em todos os lugares que acessamos `worker.thread`. O Rust idiomático usa `Option` bastante, mas quando você se encontra envolvendo algo em `Option` como uma solução alternativa, mesmo sabendo que o item sempre estará presente, é uma boa ideia procurar abordagens alternativas. Elas podem tornar seu código mais limpo e menos propenso a erros.

Nesse caso, há uma alternativa melhor: o método `Vec::drain`. Ele aceita um parâmetro de intervalo para especificar quais itens remover do `Vec` e retorna um iterador desses itens. Passar a sintaxe de intervalo `..` removerá *todos* os valores do `Vec`.

Então, precisamos atualizar a implementação de `drop` de `ThreadPool` assim:

*Arquivo: src/lib.rs*

```rust
use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: mpsc::Sender<Job>,
}

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    /// Cria um novo ThreadPool.
    ///
    /// O tamanho é o número de threads no pool.
    ///
    /// # Panics
    ///
    /// A função `new` entrará em pânico se o tamanho for zero.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool { workers, sender }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        for worker in self.workers.drain(..) {
            println!("Desligando worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {id} recebeu um trabalho; executando.");

            job();
        });

        Worker { id, thread }
    }
}
```

Isso resolve o erro do compilador e não requer nenhuma outra alteração em nosso código.

### Sinalizando para as Threads Pararem de Escutar por Trabalhos

Com todas as alterações que fizemos, nosso código compila sem nenhum aviso. No entanto, a má notícia é que este código ainda não funciona da maneira que queremos. A chave é a lógica nas *closures* executadas pelas *threads* das instâncias `Worker`: no momento, chamamos `join`, mas isso não desligará as *threads* porque elas fazem um `loop` infinito procurando por trabalhos. Se tentarmos descartar nosso `ThreadPool` com nossa implementação atual de `drop`, a *thread* principal bloqueará para sempre esperando a primeira *thread* terminar.

Para corrigir esse problema, precisaremos de uma mudança na implementação de `drop` de `ThreadPool` e, em seguida, uma mudança no loop de `Worker`.

Primeiro, mudaremos a implementação de `drop` de `ThreadPool` para descartar explicitamente o `sender` antes de esperar que as *threads* terminem. A Listagem 21-23 mostra as alterações em `ThreadPool` para descartar explicitamente `sender`. Ao contrário dos `workers`, aqui *precisamos* usar um `Option` para poder mover `sender` para fora de `ThreadPool` com `Option::take`.

*Arquivo: src/lib.rs*

```rust
use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec<Worker>,
   sender: Option<mpsc::Sender<Job>>,
}
// --corte--

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    /// Cria um novo ThreadPool.
    ///
    /// O tamanho é o número de threads no pool.
    ///
    /// # Panics
    ///
    /// A função `new` entrará em pânico se o tamanho for zero.
  pub fn new(size: usize) -> ThreadPool {
        // --corte--

        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }
    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        drop(self.sender.take());

        for worker in self.workers.drain(..) {
            println!("Desligando worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {id} recebeu um trabalho; executando.");

            job();
        });

        Worker { id, thread }
    }
}

```

*Listagem 21-23: Descartando explicitamente `sender` antes de fazer join nas threads do worker*

Descartar `sender` fecha o canal, o que indica que nenhuma outra mensagem será enviada. Quando isso acontece, todas as chamadas para `recv` que os *workers* fazem no loop infinito retornarão um erro. Na Listagem 21-24, mudamos o loop de `Worker` para sair graciosamente do loop nesse caso, o que significa que as *threads* terminarão quando a implementação de `drop` de `ThreadPool` chamar `join` nelas.

*Arquivo: src/lib.rs*

```rust
 use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: Option<mpsc::Sender<Job>>,
}

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    /// Cria um novo ThreadPool.
    ///
    /// O tamanho é o número de threads no pool.
    ///
    /// # Panics
    ///
    /// A função `new` entrará em pânico se o tamanho for zero.
     pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        drop(self.sender.take());

        for worker in self.workers.drain(..) {
            println!("Desligando worker {}", worker.id);

            worker.thread.join().unwrap();
        }
    }
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || loop {
            let message = receiver.lock().unwrap().recv();

            match message {
                Ok(job) => {
                    println!("Worker {id} recebeu um trabalho; executando.");

                    job();
                }
                Err(_) => {
                    println!("Worker {id} desconectado; desligando.");
                    break;
                }
            }
        });

        Worker { id, thread }
    }
}
```

*Listagem 21-24: Sair explicitamente do loop quando `recv` retorna um erro*

Para ver este código em ação, vamos modificar `main` para aceitar apenas duas requisições antes de desligar graciosamente o servidor, como mostrado na Listagem 21-25.

*Arquivo: src/main.rs*

```rust
use hello::ThreadPool;
use std::{
    fs,
    io::{prelude::*, BufReader},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};

fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming().take(2) {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }

    println!("Desligando.");
}

fn handle_connection(mut stream: TcpStream) {
    let buf_reader = BufReader::new(&stream);
    let request_line = buf_reader.lines().next().unwrap().unwrap();

    let (status_line, filename) = match &request_line[..] {
        "GET / HTTP/1.1" => ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" => {
            thread::sleep(Duration::from_secs(5));
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ => ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    let contents = fs::read_to_string(filename).unwrap();
    let length = contents.len();

    let response =
        format!("{status_line}\r\nContent-Length: {length}\r\n\r\n{contents}");

    stream.write_all(response.as_bytes()).unwrap();
}

```

*Listagem 21-25: Desligar o servidor após servir duas requisições, saindo do loop*

Você não gostaria que um servidor web do mundo real desligasse após servir apenas duas requisições. Este código apenas demonstra que o desligamento gracioso e a limpeza estão funcionando corretamente.

O método `take` é definido no *trait* `Iterator` e limita a iteração aos dois primeiros itens, no máximo. O `ThreadPool` sairá de escopo no final de `main`, e a implementação de `drop` será executada.

Inicie o servidor com `cargo run` e faça três requisições. A terceira requisição deve falhar, e em seu terminal você deve ver uma saída semelhante a esta:

```text
$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.41s
     Running `target/debug/hello`
Worker 0 got a job; executing.
Desligando.
Desligando worker 0
Worker 3 got a job; executing.
Worker 1 desconectado; desligando.
Worker 2 desconectado; desligando.
Worker 3 desconectado; desligando.
Worker 0 desconectado; desligando.
Desligando worker 1
Desligando worker 2
Desligando worker 3
```

Você pode ver uma ordem diferente de *workers* e mensagens impressas. Podemos ver como este código funciona a partir das mensagens: os *workers* 0 e 3 receberam as duas primeiras requisições. O servidor parou de aceitar conexões após a segunda conexão, e a implementação de `Drop` em `ThreadPool` começa a executar antes mesmo do *worker* 3 iniciar seu trabalho. Descartar o `sender` desconecta todos os *workers* e diz a eles para desligar. Cada *worker* imprime uma mensagem quando se desconecta, e então o *thread pool* chama `join` para esperar que cada *thread* do *worker* termine.

Observe um aspecto interessante desta execução em particular: o `ThreadPool` descartou o `sender` e, antes de qualquer *worker* receber um erro, tentamos fazer *join* no *worker* 0. O *worker* 0 ainda não havia recebido um erro de `recv`, então a *thread* principal bloqueou esperando o *worker* 0 terminar. Enquanto isso, o *worker* 3 recebeu um trabalho e então todas as *threads* receberam um erro. Quando o *worker* 0 terminou, a *thread* principal esperou o resto dos *workers* terminarem. Nesse ponto, todos eles haviam saído de seus loops e parado.

Parabéns! Agora completamos nosso projeto; temos um servidor web básico que usa um *thread pool* para responder de forma assíncrona. Somos capazes de realizar um desligamento gracioso do servidor, que limpa todas as *threads* no *pool*.

Aqui está o código completo para referência:

*Arquivo: src/main.rs*

```rust
use hello::ThreadPool;
use std::{
    fs,
    io::{prelude::*, BufReader},
    net::{TcpListener, TcpStream},
    thread,
    time::Duration,
};

fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming().take(2) {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }

    println!("Desligando.");
}

fn handle_connection(mut stream: TcpStream) {
    let buf_reader = BufReader::new(&stream);
    let request_line = buf_reader.lines().next().unwrap().unwrap();

    let (status_line, filename) = match &request_line[..] {
        "GET / HTTP/1.1" => ("HTTP/1.1 200 OK", "hello.html"),
        "GET /sleep HTTP/1.1" => {
            thread::sleep(Duration::from_secs(5));
            ("HTTP/1.1 200 OK", "hello.html")
        }
        _ => ("HTTP/1.1 404 NOT FOUND", "404.html"),
    };

    let contents = fs::read_to_string(filename).unwrap();
    let length = contents.len();

    let response =
        format!("{status_line}\r\nContent-Length: {length}\r\n\r\n{contents}");

    stream.write_all(response.as_bytes()).unwrap();
}

```

*Arquivo: src/lib.rs*

```rust
use std::{
    sync::{mpsc, Arc, Mutex},
    thread,
};

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: Option<mpsc::Sender<Job>>,
}

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    /// Cria um novo ThreadPool.
    ///
    /// O tamanho é o número de threads no pool.
    ///
    /// # Panics
    ///
    /// A função `new` entrará em pânico se o tamanho for zero.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool {
            workers,
            sender: Some(sender),
        }
    }

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.as_ref().unwrap().send(job).unwrap();
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        drop(self.sender.take());

          for worker in &mut self.workers {
            println!("Desligando worker {}", worker.id);

            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}

struct Worker {
    id: usize,
    thread: Option<thread::JoinHandle<()>>,
}

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || loop {
            let message = receiver.lock().unwrap().recv();

            match message {
                Ok(job) => {
                    println!("Worker {id} recebeu um trabalho; executando.");

                    job();
                }
                Err(_) => {
                    println!("Worker {id} desconectado; desligando.");
                    break;
                }
            }
        });

        Worker {
            id,
            thread: Some(thread),
        }
    }
}

```

Poderíamos fazer mais aqui! Se você quiser continuar aprimorando este projeto, aqui estão algumas ideias:

*   Adicione mais documentação a `ThreadPool` e seus métodos públicos.
*   Adicione testes da funcionalidade da biblioteca.
*   Altere as chamadas para `unwrap` para um tratamento de erros mais robusto.
*   Use `ThreadPool` para realizar alguma tarefa diferente de servir requisições web.
*   Encontre um crate de *thread pool* em crates.io e implemente um servidor web semelhante usando o crate. Em seguida, compare sua API e robustez com o *thread pool* que implementamos.

## Resumo

Muito bem! Você chegou ao final do livro! Queremos agradecer por se juntar a nós neste passeio por Rust. Agora você está pronto para implementar seus próprios projetos Rust e ajudar com os projetos de outras pessoas. Tenha em mente que existe uma comunidade acolhedora de outros Rustaceans que adorariam ajudá-lo com quaisquer desafios que você encontrar em sua jornada Rust.
